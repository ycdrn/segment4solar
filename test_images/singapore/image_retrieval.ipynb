{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.8.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/durana/Documents/web-tool/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#@title imports\n",
    "\n",
    "import pandas as pd\n",
    "#import fiona\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon, LineString, GeometryCollection\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title main\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "bipv_image_links = \"/Users/durana/Documents/web-tool/test_images/singapore/links.rtf\"\n",
    "\n",
    "def nones(n) -> list:\n",
    "    return [None for _ in range(n)]\n",
    "\n",
    "class gsv_image_object(object):\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.latitude, self.longitude, self.fov, self.heading, self.pitch, self.panoID, self.date = nones(7)\n",
    "\n",
    "        # Scope 1: main data\n",
    "\n",
    "        start = url.index('/@') + 2\n",
    "        finish = url.index('/data')\n",
    "        chunks = url[start:finish].split(',')\n",
    "\n",
    "            # Latitude & Longitude\n",
    "        self.latitude, self.longitude = float(chunks[0]), float(chunks[1])\n",
    "        for chunk in chunks[3:]:\n",
    "            char = chunk[-1]\n",
    "            data = chunk[:-1]\n",
    "            if char == 'a':\n",
    "                continue\n",
    "\n",
    "            # FOV\n",
    "            if char == 'y':\n",
    "                self.fov = round(float(data), 2)\n",
    "                continue\n",
    "\n",
    "            # Heading\n",
    "            if char == 'h':\n",
    "                self.heading = round(float(data), 2)\n",
    "                continue\n",
    "\n",
    "            # Pitch\n",
    "            if char == 't':\n",
    "                self.pitch = round(float(data) - 90, 2)\n",
    "                continue\n",
    "\n",
    "        # Scope 2: additional data\n",
    "\n",
    "            # PanoID\n",
    "        self.panoID = urllib.parse.unquote(url.split(\"!1s\")[1].split(\"!2e\")[0])\n",
    "\n",
    "            # Date\n",
    "            # Pedram: This part is to extract the date for old GSV photos.\n",
    "            # The GSV Static API doesn't yet have an implementation for\n",
    "            # old photos, but keeping this here in case they add it.\n",
    "        if '!5s' in url and 'T000000' in url:\n",
    "            start = url.index('!5s') + 3\n",
    "            finish = url.index('T000000')\n",
    "            chunk = url[start:finish]\n",
    "            self.date = f\"{chunk[:4]}-{chunk[4:6]}\"\n",
    "    def __str__(self) -> str:\n",
    "        return f\"location: ({self.latitude},{self.longitude}), fov: {self.fov}, heading: {self.heading}, pitch: {self.pitch}, panoID: {self.panoID}, date: {self.date}\"\n",
    "\n",
    "with open(bipv_image_links, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "df_index = -1\n",
    "project_index = None\n",
    "gsv_link = None\n",
    "loose_links = []\n",
    "\n",
    "prev = False\n",
    "df = pd.DataFrame(columns=['project_index', 'gsv_link', 'loose_links'])\n",
    "\n",
    "for counter, line in enumerate(lines):\n",
    "    # value type 1: index integer\n",
    "    if line.startswith('>'):\n",
    "\n",
    "        # consolidate loose links from the previous index if they exist\n",
    "        # consolidate GSV link from the previous index if it exists\n",
    "        if prev:\n",
    "            df.at[df_index, 'project_index'] = project_index\n",
    "\n",
    "            df.at[df_index, 'loose_links'] = loose_links\n",
    "            df.at[df_index, 'loose_links_count'] = int(len(loose_links))\n",
    "\n",
    "            df.at[df_index, 'gsv_link'] = gsv_link\n",
    "            if gsv_link:\n",
    "                gsv_image = gsv_image_object(gsv_link)\n",
    "                df.at[df_index, 'gsv_latitude'] = gsv_image.latitude\n",
    "                df.at[df_index, 'gsv_longitude'] = gsv_image.longitude\n",
    "                df.at[df_index, 'gsv_fov'] = gsv_image.fov\n",
    "                df.at[df_index, 'gsv_heading'] = gsv_image.heading\n",
    "                df.at[df_index, 'gsv_pitch'] = gsv_image.pitch\n",
    "                df.at[df_index, 'gsv_panoID'] = gsv_image.panoID\n",
    "                df.at[df_index, 'gsv_date'] = gsv_image.date\n",
    "\n",
    "            # clear values for next batch\n",
    "            project_index, gsv_link = None, None\n",
    "            loose_links = []\n",
    "\n",
    "        if line == '>end':\n",
    "            continue\n",
    "\n",
    "        # collect new indices and update\n",
    "        df_index += 1\n",
    "        project_index = line[1:].strip()\n",
    "\n",
    "        if prev == False:\n",
    "            prev = True\n",
    "\n",
    "        continue\n",
    "\n",
    "    # value type 2: google street view link\n",
    "    if 'https://www.google.com/maps' in line:\n",
    "        gsv_link = line\n",
    "\n",
    "        continue\n",
    "\n",
    "    # value type 3: loose image link from the web\n",
    "    loose_links.append(line)\n",
    "\n",
    "    continue\n",
    "\n",
    "df['loose_links_count'] = df['loose_links_count'].astype(int)\n",
    "\n",
    "image_link_df = df.copy()\n",
    "df = None\n",
    "\n",
    "print(image_link_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
